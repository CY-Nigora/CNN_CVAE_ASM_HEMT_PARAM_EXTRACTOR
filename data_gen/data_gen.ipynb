{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed5ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is part of the ADS Parameter Fitting project.\n",
    "# must be used under ADS integrated Python env (A)\n",
    "# namely, ..\\ADS_install_path\\tools\\python\\python.exe --> Python 3.13.2\n",
    "# TODO: whole script is run in Jupyter because ADS python ADI only\n",
    "# supports IPython kernel !!!\n",
    "\n",
    "# packages to build DIR env\n",
    "import os, json\n",
    "# set ads dict: HPEESOF_DIR and home director : HOME\n",
    "os.environ['HPEESOF_DIR'] = 'D:/ADS/install'\n",
    "os.environ['HOME'] = 'D:/ADS/dir'\n",
    "\n",
    "# packages to import ADS\n",
    "from keysight.ads import de\n",
    "from keysight.ads.de import db_uu as db\n",
    "from keysight.edatoolbox import ads\n",
    "import keysight.ads.dataset as dataset\n",
    "from keysight.edatoolbox import util\n",
    "from pathlib import Path\n",
    "from IPython.core import getipython\n",
    "\n",
    "# packages to import data analysis and save\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "# packages to multiprocessing\n",
    "# add current working directory\n",
    "import sys\n",
    "cur_path = \"E:/personal_Data/Document of School/Uni Stuttgart/Masterarbeit/Code/param_regression/ADS_Parameter_Fitting/IV_param_regression/data_gen\"\n",
    "sys.path.append(cur_path)\n",
    "\n",
    "# more meaningful data generator based on log-uniform distribution\n",
    "from log_data_gen import param_random_generator as param_random_generator_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5189c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary class and functions\n",
    "\n",
    "class PyADS():\n",
    "    def __init__(self):\n",
    "        self.HPEESOF_DIR = 'D:/ADS/install'\n",
    "        self.HOME = 'D:/ADS/dir'\n",
    "        self.cur_workspace_path = None\n",
    "        self.workspace = None\n",
    "        self.cur_library_name = None\n",
    "        self.library = None\n",
    "        self.cur_design_name = None\n",
    "        self.design = None\n",
    "\n",
    "    def create_and_open_an_empty_workspace(self, workspace_path: str):\n",
    "    # example : workspace_path = \"C:/ADS_Python_Tutorials/tutorial1_wrk\"\n",
    "    # Ensure there isn't already a workspace open\n",
    "        if de.workspace_is_open():\n",
    "            de.close_workspace()\n",
    "    \n",
    "        # Cannot create a workspace if the directory already exists\n",
    "        if os.path.exists(workspace_path):\n",
    "            raise RuntimeError(f\"Workspace directory already exists: {workspace_path}\")\n",
    "    \n",
    "        # Create the workspace\n",
    "        workspace = de.create_workspace(workspace_path)\n",
    "        # Open the workspace\n",
    "        workspace.open()\n",
    "        # Return the open workspace and close when it finished\n",
    "        return workspace\n",
    "    \n",
    "    def create_a_library_and_add_it_to_the_workspace(self, workspace: de.Workspace, library_name: str) -> None:\n",
    "        #assert workspace.path is not None\n",
    "        # Libraries can only be added to an open workspace\n",
    "        assert workspace.is_open\n",
    "        # We'll create a library in the directory of the workspace\n",
    "        library_path = workspace.path / library_name\n",
    "        # Create the library\n",
    "        de.create_new_library(library_name, library_path)\n",
    "        # And add it to the workspace (update lib.defs)\n",
    "        workspace.add_library(library_name, library_path, de.LibraryMode.SHARED)\n",
    "        lib=workspace.open_library(library_name,library_path,de.LibraryMode.SHARED)\n",
    "        return lib\n",
    "\n",
    "    def schematic_simulation(self, workspace_path: str, library_name: str, design_name: str, instance_name: str, var_dict: dict, vgs_bias_param_sweep_name: str, vds_bias_param_sweep_name: str, vgs_bias_simulation_name: str, vds_bias_simulation_name: str) -> None:\n",
    "        ''' Load Path and files, Edit the design variables, Simulate the design, and return the dataset '''\n",
    "\n",
    "        # >> Load Path and files\n",
    "        if not os.path.exists(workspace_path):\n",
    "            raise RuntimeError(f\"Workspace directory doesn't exist: {workspace_path}\")\n",
    "        if de.workspace_is_open():\n",
    "            de.close_workspace()\n",
    "        \n",
    "        # Open the workspace\n",
    "        # if (not self.workspace) or (self.cur_workspace_path != workspace_path):\n",
    "        self.workspace = de.open_workspace(workspace_path)\n",
    "        self.cur_workspace_path = workspace_path\n",
    "        # Open the library\n",
    "        # if (not self.library) or (self.cur_library_name != library_name):\n",
    "        self.library = self.workspace.open_library(lib_name=library_name, mode=de.LibraryMode.SHARED)\n",
    "        self.cur_library_name = library_name\n",
    "        # Open the design\n",
    "        # if (not self.design) or (self.cur_design_name != design_name):\n",
    "        self.design = db.open_design((library_name, design_name, \"schematic\"), db.DesignMode.APPEND)\n",
    "        self.cur_design_name = design_name\n",
    "\n",
    "        # >> Edit the design variables\n",
    "        # edit VAR\n",
    "        v = self.design.get_instance(inst_name=instance_name)\n",
    "        assert v.is_var_instance\n",
    "        for var_name in var_dict:\n",
    "            v.vars[var_name] = var_dict[var_name]\n",
    "        # Save the design\n",
    "        self.design.save_design()\n",
    "        # Simulate the design\n",
    "        output_dir = os.path.join(self.workspace.path, \"output\")\n",
    "        netlist_file = os.path.join(output_dir, \"data_gen.ckt\")\n",
    "        output_file =  os.path.join(output_dir, \"data_gen.ckt.out\")\n",
    "        # create the simulation output directory\n",
    "        util.safe_makedirs(output_dir)\n",
    "\n",
    "        # >> Simulate and return the dataset\n",
    "        ipython = getipython.get_ipython()\n",
    "        if ipython is None:\n",
    "            print(\"The remaining portion of the script must be run in an IPython environment. Exiting.\")\n",
    "            return\n",
    "        # capture the netlist in a string\n",
    "        netlist = self.design.generate_netlist()\n",
    "        # access to the simulator object to run netlists\n",
    "        simulator = ads.CircuitSimulator()\n",
    "        # run the netlist, this will block output\n",
    "        simulator.run_netlist(netlist, output_dir=output_dir, netlist_file=netlist_file, output_file=output_file)\n",
    "        output_data = dataset.open(Path(os.path.join(output_dir, f\"{design_name}.ds\")))\n",
    "        \n",
    "        # >> return data in pandas DataFrame format\n",
    "        # <class 'pandas.core.frame.DataFrame'>\n",
    "        data_ids_vds = output_data[f'{vgs_bias_param_sweep_name}.{vgs_bias_simulation_name}.DC'].to_dataframe().reset_index()\n",
    "        data_ids_vgs = output_data[f'aele_0.{vds_bias_param_sweep_name}.{vds_bias_simulation_name}'].to_dataframe().reset_index()\n",
    "        return data_ids_vds, data_ids_vgs\n",
    "    \n",
    "\n",
    "\n",
    "    def dataset_reshape(self, pd_data_IV: pd.DataFrame, pd_data_gm: pd.DataFrame, IV_dimension: list, gm_dimension: list, var_dict: dict):\n",
    "        ''' reshape the dataset into desired input matrix and output vector '''\n",
    "        IV_row_count = IV_dimension[0] # Vgs\n",
    "        IV_col_count = IV_dimension[1] # Vds\n",
    "        gm_row_count = gm_dimension[0] # Vds\n",
    "        gm_col_count = gm_dimension[1] # Vgs\n",
    "\n",
    "        output_x_IV = np.empty((IV_row_count, IV_col_count),dtype=np.float64)\n",
    "        output_x_gm = np.empty((gm_row_count, gm_col_count),dtype=np.float64)\n",
    "        output_y = np.empty((len(var_dict), 1),dtype=np.float64)\n",
    "\n",
    "        for row in range(IV_row_count):\n",
    "            output_x_IV[row, :] = pd_data_IV.loc[pd_data_IV['VGS'] == (row + 1), 'IDS.i'].to_numpy()\n",
    "        for col in range(gm_col_count):\n",
    "            output_x_gm[:, col] = pd_data_gm.loc[pd_data_gm['VGS'] == (col + 1.5), 'gm'].to_numpy()\n",
    "        for index, item in enumerate(var_dict):\n",
    "            output_y[index, 0] = var_dict[item]\n",
    "\n",
    "        return output_x_IV, output_x_gm, output_y\n",
    "    \n",
    "\n",
    "def param_random_generator(param_range: dict):\n",
    "    ''' generate a random parameter set for the HEMT model '''\n",
    "    # define the parameter range\n",
    "    # param_range = {\n",
    "    #     'VOFF': (-1.2, 2.6),\n",
    "    #     'U0': (0, 2.2),\n",
    "    #     'NS0ACCS': (1e15, 1e20),\n",
    "    #     'NFACTOR': (0.1, 5),\n",
    "    #     'ETA0': (0, 1),\n",
    "    #     'VSAT': (5e4, 1e7),\n",
    "    #     'VDSCALE': (0.5, 1e6),\n",
    "    #     'CDSCD': (1e-5, 0.75),\n",
    "    #     'LAMBDA': (0, 0.2),\n",
    "    #     'MEXPACCD': (0.05, 12),\n",
    "    #     'DELTA': (2, 100)\n",
    "    # }\n",
    "    # generate random parameters\n",
    "    var_dict = {key: str(np.random.uniform(low=val[0], high=val[1])) for key, val in param_range.items()}\n",
    "    return var_dict\n",
    "\n",
    "def init_h5_file(h5_path, x_iv_shape, x_gm_shape, y_shape,\n",
    "                 dtype_x=np.float64, dtype_y=np.float64):\n",
    "    with h5py.File(h5_path, 'w') as f:\n",
    "        # X: [num_samples, m, n]\n",
    "        f.create_dataset(\n",
    "            'X_iv',\n",
    "            shape=(0, x_iv_shape[0], x_iv_shape[1]),\n",
    "            maxshape=(None, x_iv_shape[0], x_iv_shape[1]),\n",
    "            dtype=dtype_x\n",
    "        )\n",
    "        f.create_dataset(\n",
    "            'X_gm',\n",
    "            shape=(0, x_gm_shape[0], x_gm_shape[1]),\n",
    "            maxshape=(None, x_gm_shape[0], x_gm_shape[1]),\n",
    "            dtype=dtype_x\n",
    "        )\n",
    "        # Y: [num_samples, y_len]\n",
    "        f.create_dataset(\n",
    "            'Y',\n",
    "            shape=(0, y_shape[0], 1),\n",
    "            maxshape=(None, y_shape[0], 1),\n",
    "            dtype=dtype_y\n",
    "        )\n",
    "\n",
    "def append_to_h5(h5_path, x_iv_new, x_gm_new, y_new):\n",
    "    x_iv_new = np.asarray(x_iv_new, dtype=np.float64)\n",
    "    x_gm_new = np.asarray(x_gm_new, dtype=np.float64)\n",
    "    y_new = np.asarray(y_new, dtype=np.float64)\n",
    "\n",
    "    # 确保 y_new 是二维 (batch_size, y_len)\n",
    "    if y_new.ndim == 2:\n",
    "        y_new = y_new.reshape(-1, 1)\n",
    "    else:\n",
    "        raise RuntimeError(f\"y_new must be vector, but got shape {y_new.shape}\")\n",
    "\n",
    "    with h5py.File(h5_path, 'a') as f:\n",
    "        ds_x_iv = f['X_iv']\n",
    "        ds_x_gm = f['X_gm']\n",
    "        ds_y = f['Y']\n",
    "\n",
    "        cur_len = ds_x_iv.shape[0]\n",
    "        new_len = cur_len + 1\n",
    "\n",
    "        # 扩展\n",
    "        ds_x_iv.resize(new_len, axis=0)\n",
    "        ds_x_gm.resize(new_len, axis=0)\n",
    "        ds_y.resize(new_len, axis=0)\n",
    "\n",
    "        # 赋值\n",
    "        ds_x_iv[cur_len:new_len, :, :] = x_iv_new\n",
    "        ds_x_gm[cur_len:new_len, :, :] = x_gm_new\n",
    "        ds_y[cur_len:new_len, :] = y_new\n",
    "\n",
    "\n",
    "def singel_process_iteration_data_gen2h5(workspace_path: str, validate_dict: dict, library_name: str, design_name: str, instance_name: str, param_range: dict, vgs_bias_param_sweep_name: str, vds_bias_param_sweep_name: str, vgs_bias_simulation_name: str, vds_bias_simulation_name: str, iteration_num: int, process_id: int, save_path: str, dtype_x=np.float64, dtype_y=np.float64):\n",
    "    ''' generate dataset in single process iteration '''\n",
    "    # create an instance of the PyADS class\n",
    "    ads_ctrl = PyADS()\n",
    "    X_iv_shape = [7,121]\n",
    "    X_gm_shape = [121,6]\n",
    "    # X_iv_shape = [7,186]\n",
    "    # X_gm_shape = [186,6]\n",
    "    Y_shape = [11,1]\n",
    "\n",
    "    # init h5 file\n",
    "    init_h5_file(f\"{save_path}\\\\dataset_process_{process_id}.h5\", X_iv_shape, X_gm_shape, Y_shape)\n",
    "\n",
    "    for i in range(iteration_num):\n",
    "        start_time = time.time()\n",
    "        if validate_dict:\n",
    "            var_dict = validate_dict\n",
    "        else:\n",
    "            # var_dict = param_random_generator(param_range)\n",
    "            var_dict = param_random_generator_log(param_range) # use log-uniform distribution based generator\n",
    "        pd_data_vgs_bias, pd_data_gm = ads_ctrl.schematic_simulation(\n",
    "            workspace_path,\n",
    "            library_name,\n",
    "            design_name,\n",
    "            instance_name,\n",
    "            var_dict,\n",
    "            vgs_bias_param_sweep_name,\n",
    "            vds_bias_param_sweep_name,\n",
    "            vgs_bias_simulation_name,\n",
    "            vds_bias_simulation_name\n",
    "        )\n",
    "        X_iv, X_gm, y = ads_ctrl.dataset_reshape(pd_data_vgs_bias, pd_data_gm, X_iv_shape, X_gm_shape, var_dict)\n",
    "        end_time = time.time()\n",
    "        print(f' >> Process {process_id} :: Loop {i + 1}/{iteration_num} :: used time:', round(end_time - start_time, 2), 's')\n",
    "\n",
    "        try:\n",
    "            append_to_h5(f\"{save_path}\\\\dataset_process_{process_id}.h5\", X_iv, X_gm, y)\n",
    "        except:\n",
    "            print(f\"【ERROR】Error appending data in process {process_id} at iteration {i + 1}.\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE VARIABLES\n",
    "\n",
    "workspace_path = \"E:\\\\personal_Data\\\\Document of School\\\\Uni Stuttgart\\\\Masterarbeit\\\\Simulation\\\\ADS\\\\ASM_HEMT1_wrk_1_Jia\"\n",
    "validate_dict = None\n",
    "library_name = \"IAF_pGaN_lib\"\n",
    "design_name = \"gs66508bv1_Pytest_simple_paramset\"\n",
    "instance_name = \"IV\"\n",
    "var_dict = {'VOFF':'1.785', 'U0':'0.424', 'NS0ACCS':'2e+17', 'NFACTOR':'1', 'ETA0':'0.06', 'VSAT':'8e+4', 'VDSCALE':'5', 'CDSCD':'0.1', 'LAMBDA':'0.01', 'MEXPACCD':'1.5', 'DELTA':'3'}\n",
    "param_range = {\n",
    "        'VOFF': (-1.2, 2.6),\n",
    "        'U0': (0, 2.2),\n",
    "        'NS0ACCS': (1e15, 1e20),\n",
    "        'NFACTOR': (0.1, 5),\n",
    "        'ETA0': (0, 1),\n",
    "        'VSAT': (5e4, 1e7),\n",
    "        'VDSCALE': (0.5, 1e6),\n",
    "        'CDSCD': (1e-5, 0.75),\n",
    "        'LAMBDA': (0, 0.2),\n",
    "        'MEXPACCD': (0.05, 12),\n",
    "        'DELTA': (2, 100)\n",
    "    }\n",
    "vgs_bias_param_sweep_name = 'Sweep_vgs'\n",
    "vds_bias_param_sweep_name = 'Sweep_vds'\n",
    "vgs_bias_simulation_name = 'DC1'\n",
    "vds_bias_simulation_name = 'DC2'\n",
    "iteration_num = 1000\n",
    "process_id = 1\n",
    "data_save_path = \"C:\\\\Users\\\\97427\\\\Desktop\\\\testttttttttttttt\"\n",
    "\n",
    "# for multiprocessing\n",
    "process_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d05bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to run the data generation - single process\n",
    "\n",
    "singel_process_iteration_data_gen2h5(\n",
    "    workspace_path, \n",
    "    validate_dict,\n",
    "    library_name, \n",
    "    design_name, \n",
    "    instance_name,\n",
    "    param_range, \n",
    "    vgs_bias_param_sweep_name,\n",
    "    vds_bias_param_sweep_name,\n",
    "    vgs_bias_simulation_name,\n",
    "    vds_bias_simulation_name,\n",
    "    iteration_num,\n",
    "    process_id, \n",
    "    data_save_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb45e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to run the data generation - single process \n",
    "# 1000 samples\n",
    "\n",
    "total_iteration_num = 10\n",
    "\n",
    "for iter in range(total_iteration_num):\n",
    "    process_id = iter + 1\n",
    "    singel_process_iteration_data_gen2h5(\n",
    "    workspace_path, \n",
    "    validate_dict,\n",
    "    library_name, \n",
    "    design_name, \n",
    "    instance_name,\n",
    "    param_range, \n",
    "    vgs_bias_param_sweep_name,\n",
    "    vds_bias_param_sweep_name,\n",
    "    vgs_bias_simulation_name,\n",
    "    vds_bias_simulation_name,\n",
    "    iteration_num,\n",
    "    process_id, \n",
    "    data_save_path\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c49871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to run the data generation - multi-processing\n",
    "\n",
    "# create parameter vector for multiple processes\n",
    "param_vector = [(workspace_path, \n",
    "                validate_dict,\n",
    "                library_name, \n",
    "                design_name, \n",
    "                instance_name,\n",
    "                param_range, \n",
    "                vgs_bias_param_sweep_name,\n",
    "                vds_bias_param_sweep_name,\n",
    "                vgs_bias_simulation_name,\n",
    "                vds_bias_simulation_name,\n",
    "                iteration_num,\n",
    "                process_id, \n",
    "                data_save_path) \n",
    "                for process_id in range(1, process_count + 1)]\n",
    "\n",
    "# run the data generation in multiple processes\n",
    "# try:\n",
    "Parallel(n_jobs=4, backend=\"loky\")(delayed(singel_process_iteration_data_gen2h5)(*p) for p in param_vector)\n",
    "# except:\n",
    "#     raise ConnectionError(f\"Error in parallel processing. Please check the parameters and the ADS environment.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b511f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This part is only for testing, to verify the content of saved data\n",
    "\n",
    "# load data\n",
    "# with h5py.File(f\"{data_save_path}\\\\dataset_process_x.h5\", 'r') as f:\n",
    "with h5py.File(f\"{data_save_path}\\\\dataset_process_{9999}.h5\", 'r') as f:\n",
    "    print('data structure: ', f.keys())\n",
    "    print('X_iv shape: ', f['X_iv'].shape)\n",
    "    print('X_gm shape: ', f['X_gm'].shape)\n",
    "    print('Y shape: ', f['Y'].shape)\n",
    "\n",
    "\n",
    "    test_index = 1\n",
    "    test_index -= 1\n",
    "\n",
    "    legend_values = np.linspace(-3.5, 15, f['X_gm'].shape[1])  \n",
    "    # create colormap\n",
    "    cmap = plt.cm.gist_ncar\n",
    "    norm = plt.Normalize(vmin=legend_values.min(), vmax=legend_values.max())\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 8)) \n",
    "    for i in range(f['X_iv'].shape[1]):\n",
    "        ax[0].plot(np.linspace(-3.5, 15, f['X_gm'].shape[1]) , f['X_iv'][test_index,i,:].flatten() , label=f\"VGS={i+1} V\")\n",
    "        ax[0].legend()\n",
    "        ax[0].grid()\n",
    "        ax[0].set_title('test plot of I-V')\n",
    "        ax[0].set_xlabel(\"VDS (V)\")\n",
    "        ax[0].set_ylabel(\"IDS (A)\")\n",
    "    for i in range(f['X_gm'].shape[1]):\n",
    "        color = cmap(norm(legend_values[i]))\n",
    "        ax[1].plot(np.arange(1.5, 7.5, 1.0), f['X_gm'][test_index,i,:], color=color)\n",
    "        ax[1].grid(True)\n",
    "        ax[1].set_title('test plot of gm')\n",
    "        ax[1].set_xlabel(\"VGS (V)\")\n",
    "        ax[1].set_ylabel(\"gm\")\n",
    "    # 加颜色条\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  # 仅用于colorbar\n",
    "    cbar = fig.colorbar(sm, ax=ax)\n",
    "    cbar.set_label(\"VDS (V)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc45f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing: verify gm from both Ids-Vds and Ids-Vgs\n",
    "\n",
    "process_id = 1\n",
    "test_index = 1\n",
    "\n",
    "with h5py.File(f\"{data_save_path}\\\\dataset_process_{process_id}.h5\", 'r') as f:\n",
    "\n",
    "    gm_test = np.empty((121,6), dtype=np.float64)\n",
    "    for i in range(121):\n",
    "        for j in range(6):\n",
    "            gm_test[i,j] = f['X_iv'][test_index, j+1, i] - f['X_iv'][test_index, j, i]\n",
    "        \n",
    "    legend_values = np.linspace(-3.5, 20, f['X_gm'].shape[1])  \n",
    "    # create colormap\n",
    "    cmap = plt.cm.gist_ncar\n",
    "    norm = plt.Normalize(vmin=legend_values.min(), vmax=legend_values.max())\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 8)) \n",
    "    for i in range(f['X_gm'].shape[1]):\n",
    "        # plot 1\n",
    "        color = cmap(norm(legend_values[i]))\n",
    "        ax[0].plot(np.arange(1.5, 7.5, 1.0), gm_test[i,:], color=color)\n",
    "        ax[0].grid(True)\n",
    "        ax[0].set_title('gm from Ids-Vds')\n",
    "        ax[0].set_xlabel(\"VGS (V)\")\n",
    "        ax[0].set_ylabel(\"gm\")\n",
    "        # plot 2\n",
    "        color = cmap(norm(legend_values[i]))\n",
    "        ax[1].plot(np.arange(1.5, 7.5, 1.0), f['X_gm'][test_index,i,:], color=color)\n",
    "        ax[1].grid(True)\n",
    "        ax[1].set_title('gm from Ids-Vgs')\n",
    "        ax[1].set_xlabel(\"VGS (V)\")\n",
    "        ax[1].set_ylabel(\"gm\")\n",
    "        # plot 3\n",
    "        ax[2].plot(np.arange(1.5, 7.5, 1.0), f['X_gm'][test_index,i,:] - gm_test[i,:], color=color)\n",
    "        ax[2].grid(True)\n",
    "        ax[2].set_title('error of both way to get gm')\n",
    "        ax[2].set_xlabel(\"VGS (V)\")\n",
    "        ax[2].set_ylabel(\"error\")\n",
    "\n",
    "    # add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  # only for colorbar\n",
    "    cbar = fig.colorbar(sm, ax=ax)\n",
    "    cbar.set_label(\"VDS (V)\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
